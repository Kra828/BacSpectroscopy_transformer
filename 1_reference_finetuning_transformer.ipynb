{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning on the reference dataset (Transformer)\n",
    "本 notebook 使用 Transformer 替换 ResNet CNN，对 30 种菌株的 Raman 光谱进行微调演示，与原始 notebook 步骤一致，仅修改模型实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "t00 = time()\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.1+cu128\n",
      "True\n",
      "NVIDIA GeForce RTX 5090\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)                 # 应显示 cu121 / cu122 等后缀\n",
    "print(torch.cuda.is_available())         # True\n",
    "print(torch.cuda.get_device_name(0))     # 'NVIDIA GeForce RTX 5090'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 1000) (3000,)\n"
     ]
    }
   ],
   "source": [
    "X_fn = './data/X_finetune.npy'\n",
    "y_fn = './data/y_finetune.npy'\n",
    "X = np.load(X_fn)\n",
    "y = np.load(y_fn)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading pre-trained Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer import SpectraTransformer\n",
    "import os, torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kra\\anaconda3\\envs\\jupyter\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Transformer parameters\n",
    "input_dim = 1000\n",
    "n_classes = 30\n",
    "d_model = 128\n",
    "nhead = 4\n",
    "num_layers = 4\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '{}'.format(0)\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "model = SpectraTransformer(input_dim=input_dim, d_model=d_model, nhead=nhead,\n",
    "    num_layers=num_layers, n_classes=n_classes)\n",
    "if cuda: model.cuda()\n",
    "# 如有已训练 checkpoint，可在此载入\n",
    "ckpt_path = './pretrained_transformer_model.ckpt'\n",
    "if os.path.exists(ckpt_path):\n",
    "    model.load_state_dict(torch.load(ckpt_path, map_location=lambda s,l: s), strict=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fine-tuning!\n",
      "Epoch 1: Train 3.37%  Val 3.33%\n",
      "Epoch 2: Train 3.56%  Val 1.67%\n",
      "Epoch 3: Train 4.22%  Val 5.00%\n",
      "Epoch 4: Train 6.33%  Val 4.67%\n",
      "Epoch 5: Train 11.04%  Val 15.33%\n",
      "Epoch 6: Train 18.56%  Val 15.00%\n",
      "Epoch 7: Train 24.26%  Val 24.00%\n",
      "Epoch 8: Train 28.41%  Val 23.33%\n",
      "Epoch 9: Train 32.93%  Val 35.67%\n",
      "Epoch 10: Train 39.96%  Val 44.67%\n",
      "Epoch 11: Train 46.63%  Val 30.33%\n",
      "Epoch 12: Train 49.41%  Val 52.67%\n",
      "Epoch 13: Train 53.81%  Val 56.00%\n",
      "Epoch 14: Train 56.07%  Val 55.00%\n",
      "Epoch 15: Train 60.74%  Val 64.33%\n",
      "Epoch 16: Train 62.52%  Val 61.33%\n",
      "Epoch 17: Train 63.33%  Val 58.67%\n",
      "Epoch 18: Train 65.56%  Val 58.00%\n",
      "Epoch 19: Train 67.33%  Val 67.33%\n",
      "Epoch 20: Train 68.41%  Val 67.00%\n",
      "Epoch 21: Train 69.85%  Val 63.00%\n",
      "Epoch 22: Train 72.19%  Val 71.33%\n",
      "Epoch 23: Train 73.63%  Val 71.67%\n",
      "Epoch 24: Train 73.78%  Val 76.33%\n",
      "Epoch 25: Train 74.59%  Val 72.33%\n",
      "Epoch 26: Train 75.00%  Val 75.33%\n",
      "Epoch 27: Train 76.85%  Val 69.00%\n",
      "Epoch 28: Train 78.00%  Val 71.33%\n",
      "Epoch 29: Train 79.85%  Val 73.00%\n",
      "Epoch 30: Train 79.89%  Val 73.67%\n",
      "Epoch 31: Train 81.52%  Val 78.33%\n",
      "Epoch 32: Train 81.37%  Val 74.33%\n",
      "Epoch 33: Train 83.30%  Val 71.67%\n",
      "Epoch 34: Train 82.52%  Val 80.67%\n",
      "Epoch 35: Train 85.15%  Val 81.33%\n",
      "Epoch 36: Train 84.56%  Val 79.00%\n",
      "Epoch 37: Train 86.44%  Val 81.67%\n",
      "Epoch 38: Train 86.22%  Val 68.33%\n",
      "Epoch 39: Train 86.85%  Val 81.00%\n",
      "Epoch 40: Train 88.70%  Val 83.33%\n",
      "Epoch 41: Train 89.26%  Val 81.67%\n",
      "Epoch 42: Train 89.41%  Val 62.33%\n",
      "Epoch 43: Train 87.85%  Val 82.33%\n",
      "Epoch 44: Train 88.81%  Val 80.67%\n",
      "Epoch 45: Train 90.37%  Val 77.67%\n",
      "Epoch 46: Train 90.11%  Val 84.00%\n",
      "Epoch 47: Train 91.00%  Val 82.67%\n",
      "Epoch 48: Train 91.26%  Val 83.67%\n",
      "Epoch 49: Train 93.26%  Val 76.67%\n",
      "Epoch 50: Train 92.41%  Val 84.00%\n",
      "Epoch 51: Train 93.04%  Val 79.33%\n",
      "Epoch 52: Train 93.22%  Val 83.00%\n",
      "Epoch 53: Train 92.52%  Val 84.33%\n",
      "Epoch 54: Train 93.04%  Val 84.00%\n",
      "Epoch 55: Train 92.63%  Val 79.00%\n",
      "Epoch 56: Train 92.74%  Val 83.67%\n",
      "Epoch 57: Train 93.44%  Val 75.67%\n",
      "Epoch 58: Train 94.04%  Val 85.67%\n",
      "Epoch 59: Train 94.22%  Val 85.67%\n",
      "Epoch 60: Train 95.67%  Val 79.67%\n",
      "Finished in 1673.95s, best val acc=85.67%\n"
     ]
    }
   ],
   "source": [
    "from datasets import spectral_dataloader\n",
    "from training import run_epoch\n",
    "from torch import optim\n",
    "\n",
    "# Train/val split\n",
    "p_val = 0.1\n",
    "n_val = int(len(y) * p_val)\n",
    "idxs = np.random.permutation(len(y))\n",
    "idx_val, idx_tr = idxs[:n_val], idxs[n_val:]\n",
    "\n",
    "epochs = 60  # 更换为 ~30 以达到论文精度\n",
    "batch_size = 32\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-4, betas=(0.5, 0.999))\n",
    "\n",
    "dl_tr = spectral_dataloader(X, y, idxs=idx_tr, batch_size=batch_size, shuffle=True)\n",
    "dl_val = spectral_dataloader(X, y, idxs=idx_val, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "best_val = 0\n",
    "print('Starting fine-tuning!')\n",
    "for epoch in range(epochs):\n",
    "    acc_tr, _ = run_epoch(epoch, model, dl_tr, cuda, training=True, optimizer=optimizer)\n",
    "    acc_val, _ = run_epoch(epoch, model, dl_val, cuda, training=False)\n",
    "    print(f'Epoch {epoch+1}: Train {acc_tr:.2f}%  Val {acc_val:.2f}%')\n",
    "    if acc_val > best_val:\n",
    "        best_val = acc_val\n",
    "        torch.save(model.state_dict(), 'finetuned_transformer_model.ckpt')\n",
    "\n",
    "print(f'Finished in {time() - t00:.2f}s, best val acc={best_val:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
